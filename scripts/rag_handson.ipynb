{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .envファイルの作成\n",
    "\n",
    "次のセルを実行して、環境変数を格納するための`.env`ファイルを作成してください。セルの実行は、セルの左上の再生マークをクリックすることでできます。\n",
    "\n",
    "初回実行時には、カーネルの選択を求められる場合があります。その際には、「Python 環境…」をクリックして「★Python 3.11.9…」を選択してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ..\n",
    "\n",
    "# .envファイルを作成する\n",
    "cat <<EOF > .env\n",
    "SEARCH_SERVICE_ENDPOINT=\"your_search_service_endpoint\"\n",
    "SEARCH_API_KEY=\"your_search_api_key\"\n",
    "AOAI_ENDPOINT=\"your_aoai_endpoint\"\n",
    "AOAI_API_VERSION=2024-06-01\n",
    "AOAI_API_KEY=\"your_aoai_api_key\"\n",
    "EOF\n",
    "\n",
    "echo \".envファイルが作成されました。\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境変数の設定\n",
    "Azure Portalで各環境変数を確認し、先ほど作成した`.env`ファイルに格納してください。\n",
    "\n",
    "1. `SEARCH_SERVICE_ENDPOINT,SEARCH_API_KEY`の設定\n",
    "    - `SEARCH_SERVICE_ENDPOINT`は、AI Searchリソースの「概要」タブから確認できます。\n",
    "    ![Image 1](../assets/env1.png)\n",
    "\n",
    "    - `SEARCH_API_KEY`は、AI Searchリソースの「設定」>「キー」タブから確認できます。\n",
    "    ![Image 2](../assets/env2.png)\n",
    "\n",
    "2. `AOAI_ENDPOINT,AOAI_API_KEY`の設定\n",
    "    - `AOAI_ENDPOINT,AOAI_API_KEY`は、OpenAI Servicesリソースの「リソース管理」>「キーとエンドポイント」タブから確認できます。\n",
    "    ![Image 3](../assets/env3.png)\n",
    "\n",
    "#### **※ここまで完了されたら、以降順番にセルを実行してRAGの実装を体験してみてください。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのインポート\n",
    "以下のセルで必要なライブラリをインポートします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes.models import *\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from PyPDF2 import PdfReader\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境変数の読み込み\n",
    "envファイルから環境変数を読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境変数からAzure AI Search、Azure OpenAIのエンドポイント等を取得する\n",
    "load_dotenv()\n",
    "search_endpoint = os.environ[\"SEARCH_SERVICE_ENDPOINT\"]\n",
    "search_api_key = os.environ[\"SEARCH_API_KEY\"]\n",
    "aoai_endpoint = os.environ[\"AOAI_ENDPOINT\"]\n",
    "aoai_api_version = os.environ[\"AOAI_API_VERSION\"]\n",
    "aoai_api_key = os.environ[\"AOAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure AI Searchのインデックスを作成する\n",
    "\n",
    "1. **クライアントの生成**: `SearchIndexClient`を使用して、Azure AI Searchのインデックスクライアントを作成します。\n",
    "2. **インデックスの確認**: インデックスがすでに存在する場合、再作成を避けるために何もしません。\n",
    "3. **フィールドの定義**: インデックスに含まれるフィールドを定義します。ここでは、ドキュメントID、コンテンツ、コンテンツベクトルのフィールドを設定します。\n",
    "4. **ベクトル検索の設定**: ベクトル検索の設定を行います。\n",
    "5. **インデックスの作成**: 定義した設定を用いてインデックスを作成します。\n",
    "\n",
    "以下のコードを実行して、インデックスを作成します。実行後にAI Searchのリソースの「検索管理」>「インデックス」タグでdocsというインデックスが作成されていることを確認してください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "インデックスが作成されました\n"
     ]
    }
   ],
   "source": [
    "def create_index():\n",
    "    \"\"\"\n",
    "    Azure AI Searchのインデックスを作成する\n",
    "    \"\"\"\n",
    "    client = SearchIndexClient(endpoint= search_endpoint, credential=AzureKeyCredential(search_api_key))\n",
    "    name = \"docs\"\n",
    "\n",
    "    # すでにインデックスが作成済みである場合には何もしない\n",
    "    if 'docs' in client.list_index_names():\n",
    "        print(\"すでにインデックスが作成済みです\")\n",
    "        return\n",
    "\n",
    "    # インデックスのフィールドを定義する\n",
    "    fields = [\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchableField(name=\"content\", type=\"Edm.String\", analyzer_name=\"ja.microsoft\"),\n",
    "        SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\")\n",
    "    ]\n",
    "\n",
    "    # ベクトル検索のための定義を行う\n",
    "    vector_search = VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"myHnsw\"\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"myHnswProfile\",\n",
    "                algorithm_configuration_name=\"myHnsw\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # インデックスを作成する\n",
    "    index = SearchIndex(name=name, fields=fields, vector_search=vector_search)\n",
    "    client.create_index(index)\n",
    "    print(\"インデックスが作成されました\")\n",
    "\n",
    "# インデックスを作成する\n",
    "create_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ドキュメントをAzure AI Searchにインデクシングする\n",
    "\n",
    "1. **PDFからテキストを抽出**: `PdfReader`を使用してPDFファイルからテキストを抽出します。ここでは、ドキュメントととして厚生労働省が提供する[モデル就業規則](https://www.mhlw.go.jp/content/001018385.pdf)を使用します。\n",
    "※**リポジトリをForkした際にリポジトリ名を変更された方は、`filepath`の`aoai-rag-handson`部分をご自身のリポジトリ名に変更してください。**\n",
    "2. **テキストのチャンク化**: テキストを指定したサイズでチャンクに分割します。これにより、大きなテキストを小さな部分に分けて処理しやすくします。\n",
    "3. **インデクシング**: チャンク化されたテキストをAzure AI Searchにインデックスします。ここでは、Azure OpenAIを使用してテキストのベクトルを生成し、それを含むドキュメントをAzure AI Searchにアップロードします。\n",
    "\n",
    "以下のコードを順次実行して、ドキュメントをインデックスします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/aoai-rag-handson/data/001018385.pdf内のテキストを抽出中...\n",
      "テキストの抽出が完了しました\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_docs(filepath):\n",
    "    \"\"\"\n",
    "    PDFからテキストを抽出する\n",
    "    \"\"\"\n",
    "    print(f\"{filepath}内のテキストを抽出中...\")\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        reader = PdfReader(f)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    print(\"テキストの抽出が完了しました\")\n",
    "    return text\n",
    "\n",
    "# 対象ファイルパスのファイルを読み込んで、Azure AI Searchにインデックスする\n",
    "filepath = \"/workspaces/aoai-rag-handson/data/001018385.pdf\"  # 対象ファイルパス\n",
    "content = extract_text_from_docs(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "チャンク化完了\n"
     ]
    }
   ],
   "source": [
    "def create_chunk(content: str, separator: str, chunk_size: int = 512, overlap: int = 0):\n",
    "    \"\"\"\n",
    "    テキストを指定したサイズで分割する\n",
    "    \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_overlap=overlap, chunk_size=chunk_size, separators=separator)\n",
    "    chunks = splitter.split_text(content)\n",
    "    return chunks\n",
    "\n",
    "# テキストを指定したサイズで分割する\n",
    "chunksize = 1000  # チャンクサイズ\n",
    "overlap = 200  # オーバーラップサイズ\n",
    "separator = [\"\\n\\n\", \"\\n\", \"。\", \"、\", \" \", \"\"]  # 区切り文字\n",
    "chunks = create_chunk(content, separator, chunksize, overlap)\n",
    "print(\"チャンク化完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1個目のチャンクを処理中...\n",
      "2個目のチャンクを処理中...\n",
      "3個目のチャンクを処理中...\n",
      "4個目のチャンクを処理中...\n",
      "5個目のチャンクを処理中...\n",
      "6個目のチャンクを処理中...\n",
      "7個目のチャンクを処理中...\n",
      "8個目のチャンクを処理中...\n",
      "9個目のチャンクを処理中...\n",
      "10個目のチャンクを処理中...\n",
      "11個目のチャンクを処理中...\n",
      "12個目のチャンクを処理中...\n",
      "13個目のチャンクを処理中...\n",
      "14個目のチャンクを処理中...\n",
      "15個目のチャンクを処理中...\n",
      "16個目のチャンクを処理中...\n",
      "17個目のチャンクを処理中...\n",
      "18個目のチャンクを処理中...\n",
      "19個目のチャンクを処理中...\n",
      "20個目のチャンクを処理中...\n",
      "21個目のチャンクを処理中...\n",
      "22個目のチャンクを処理中...\n",
      "23個目のチャンクを処理中...\n",
      "24個目のチャンクを処理中...\n",
      "25個目のチャンクを処理中...\n",
      "26個目のチャンクを処理中...\n",
      "27個目のチャンクを処理中...\n",
      "28個目のチャンクを処理中...\n",
      "29個目のチャンクを処理中...\n",
      "30個目のチャンクを処理中...\n",
      "31個目のチャンクを処理中...\n",
      "32個目のチャンクを処理中...\n",
      "33個目のチャンクを処理中...\n",
      "34個目のチャンクを処理中...\n",
      "35個目のチャンクを処理中...\n",
      "36個目のチャンクを処理中...\n",
      "37個目のチャンクを処理中...\n",
      "38個目のチャンクを処理中...\n",
      "39個目のチャンクを処理中...\n",
      "40個目のチャンクを処理中...\n",
      "41個目のチャンクを処理中...\n",
      "42個目のチャンクを処理中...\n",
      "43個目のチャンクを処理中...\n",
      "44個目のチャンクを処理中...\n",
      "45個目のチャンクを処理中...\n",
      "46個目のチャンクを処理中...\n",
      "47個目のチャンクを処理中...\n",
      "48個目のチャンクを処理中...\n",
      "49個目のチャンクを処理中...\n",
      "50個目のチャンクを処理中...\n",
      "51個目のチャンクを処理中...\n",
      "52個目のチャンクを処理中...\n",
      "53個目のチャンクを処理中...\n",
      "54個目のチャンクを処理中...\n",
      "55個目のチャンクを処理中...\n",
      "56個目のチャンクを処理中...\n",
      "57個目のチャンクを処理中...\n",
      "58個目のチャンクを処理中...\n",
      "59個目のチャンクを処理中...\n",
      "60個目のチャンクを処理中...\n",
      "61個目のチャンクを処理中...\n",
      "62個目のチャンクを処理中...\n",
      "63個目のチャンクを処理中...\n",
      "64個目のチャンクを処理中...\n",
      "65個目のチャンクを処理中...\n",
      "66個目のチャンクを処理中...\n",
      "67個目のチャンクを処理中...\n",
      "68個目のチャンクを処理中...\n",
      "69個目のチャンクを処理中...\n",
      "70個目のチャンクを処理中...\n",
      "71個目のチャンクを処理中...\n",
      "72個目のチャンクを処理中...\n",
      "73個目のチャンクを処理中...\n",
      "74個目のチャンクを処理中...\n",
      "75個目のチャンクを処理中...\n",
      "76個目のチャンクを処理中...\n",
      "77個目のチャンクを処理中...\n",
      "78個目のチャンクを処理中...\n",
      "79個目のチャンクを処理中...\n",
      "80個目のチャンクを処理中...\n",
      "81個目のチャンクを処理中...\n",
      "82個目のチャンクを処理中...\n",
      "83個目のチャンクを処理中...\n",
      "84個目のチャンクを処理中...\n",
      "85個目のチャンクを処理中...\n",
      "86個目のチャンクを処理中...\n",
      "87個目のチャンクを処理中...\n",
      "88個目のチャンクを処理中...\n",
      "89個目のチャンクを処理中...\n",
      "90個目のチャンクを処理中...\n",
      "91個目のチャンクを処理中...\n",
      "92個目のチャンクを処理中...\n",
      "93個目のチャンクを処理中...\n",
      "94個目のチャンクを処理中...\n",
      "95個目のチャンクを処理中...\n",
      "96個目のチャンクを処理中...\n",
      "97個目のチャンクを処理中...\n",
      "98個目のチャンクを処理中...\n",
      "99個目のチャンクを処理中...\n",
      "インデクシング完了\n"
     ]
    }
   ],
   "source": [
    "def index_docs(chunks: list):\n",
    "    \"\"\"\n",
    "    ドキュメントをAzure AI Searchにインデックスする\n",
    "    \"\"\"\n",
    "    # Azure AI SearchのAPIに接続するためのクライアントを生成する\n",
    "    searchClient = SearchClient(\n",
    "        endpoint=search_endpoint,\n",
    "        index_name=\"docs\",\n",
    "        credential=AzureKeyCredential(search_api_key)\n",
    "    )\n",
    "\n",
    "    # Azure OpenAIのAPIに接続するためのクライアントを生成する\n",
    "    openAIClient = AzureOpenAI(\n",
    "        api_key=aoai_api_key,\n",
    "        api_version=aoai_api_version,\n",
    "        azure_endpoint=aoai_endpoint\n",
    "    )\n",
    "\n",
    "    # チャンク化されたテキストとそのテキストのベクトルをAzure AI Searchにアップロードする\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"{i+1}個目のチャンクを処理中...\")\n",
    "        response = openAIClient.embeddings.create(\n",
    "            input=chunk,\n",
    "            model=\"text-embedding-3-small-deploy\"\n",
    "        )\n",
    "\n",
    "        # チャンク化されたテキストとそのテキストのベクトルをAzure AI Searchにアップロードする\n",
    "        document = {\"id\": str(i), \"content\": chunk, \"contentVector\": response.data[0].embedding}\n",
    "        searchClient.upload_documents([document])\n",
    "    print(\"インデクシング完了\")\n",
    "\n",
    "# テキストをAzure AI Searchにインデックスする\n",
    "index_docs(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## プロンプトのベクトル化\n",
    "\n",
    "1. **OpenAIクライアントの作成**: OpenAI APIに接続するためのクライアントを作成します。\n",
    "2. **プロンプトのベクトル化**: 指定したプロンプトをOpenAIモデルを使用してベクトル化します。このベクトルは、後の検索クエリとして使用されます。`prompt`については、任意のものに変更していただいても構いません。\n",
    "\n",
    "以下のコードを実行して、プロンプトをベクトル化します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ベクトル化したプロンプト[-0.007567174732685089, 0.01277646142989397, 0.07194299250841141, -0.009398650377988815, 0.03917383775115013, 0.012919032014906406, 0.012765495106577873, -0.005538294557482004, 0.021451294422149658, -0.01731676608324051, 0.0035368315875530243, 0.050316229462623596, -0.009097060188651085, 0.009820876643061638, -0.010478892363607883, -0.03226467967033386, -0.019872058182954788, -0.03000549226999283, 0.021506130695343018, 0.04116981849074364, 0.011953942477703094, 0.024368496611714363, -0.024851040914654732, 0.03366844356060028, 0.005922136828303337, -0.013522212393581867, 0.035159945487976074, -0.002153628971427679, 0.024280760437250137, -0.05062330141663551, -0.0041701714508235455, -0.04320966452360153, -0.005724732298403978, -0.008680317550897598, -0.005409433040767908, 0.03362457826733589, 0.014662771485745907, 0.026627682149410248, -0.00857613142579794, -0.0404021330177784, -0.014070558361709118, -0.020617809146642685, 0.040116991847753525, -0.07957597076892853, -0.043275464326143265, 0.044635362923145294, -0.05106198042631149, 0.06110767647624016, 0.012392619624733925, 0.04375800862908363]\n"
     ]
    }
   ],
   "source": [
    "# OpenAIクライアントの作成\n",
    "openAIClient = AzureOpenAI(\n",
    "    api_key=aoai_api_key,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_endpoint=aoai_endpoint\n",
    ")\n",
    "\n",
    "# プロンプトをベクトル化する関数\n",
    "def generate_embeddings(prompt, model=\"text-embedding-3-small-deploy\"): # model = \"deployment_name\"\n",
    "    response = openAIClient.embeddings.create(input=prompt, model=model).data[0].embedding\n",
    "    return response\n",
    "\n",
    "# プロンプトをベクトル化\n",
    "prompt = \"就業時間に関してどのような規定があるのか重要度順に3つ教えてください\"\n",
    "vectorized_prompt = generate_embeddings(prompt)\n",
    "print(f\"ベクトル化したプロンプト{vectorized_prompt[:50]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベクトル検索\n",
    "\n",
    "1. **SearchClientの作成**: Azure AI Searchに接続するためのクライアントを作成します。\n",
    "2. **ベクトル検索の準備**: ベクトルクエリを作成し、指定されたフィールドで上位の結果を取得します。\n",
    "3. **検索実行と結果取得**: 検索を実行し、最初の検索結果を取得します。\n",
    "\n",
    "以下のコードを実行して、ベクトル検索を行います。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "す。）は、１週４４時間まで働かせることが認められています（労基法第４０条、労基則\n",
      "第２５条の２）。 \n",
      "また、労基法第３２条第２項において、１日の労働時間の上限は８時間と定められて\n",
      "います。 \n",
      "３ 休憩時間については、１日の労働時間が６時間を超える場合には少なくとも４５分、\n",
      "８時間を超える場合には少なくとも１時間の休憩時間を与えなければなりません（労基\n",
      "法第３４条）。 \n",
      "４ 休日については、毎週少なくとも１回又は４週間を通じ４日以上与えなければなりま\n",
      "せん（労基法第３５条）。 \n",
      "５ 上記２から４までの労基法の規定に適合する労働条件とするためには、①週休２日制\n",
      "とする、②週休１日制で１日の所定労働時間を短く設定する、③変形労働時間制（１か\n",
      "月単位、１年単位等）を導入する等の方法がありますので、それぞれの事業場の実情に\n",
      "応じて、下記の規程例を参考に就業規則を作成してください。 \n",
      " \n",
      " \n",
      " \n",
      "［例１］ 完全週休２日制を採用する場合の規程例 \n",
      " \n",
      "１日の労働時間を８時間とし、完全週休２日制を採用する場合の規程例です。 \n",
      " \n",
      "(労働時間及び休憩時間)  \n",
      "第１９条  労働時間は、１週間については４０時間、１日については８時間とする。 \n",
      "２ 始業・終業の時刻及び休憩時間は、次のとおりとする。ただし、業務の都合その他\n",
      "やむを得ない事情により、これらを繰り上げ、又は繰り下げることがある。この場合、   \n",
      "前日までに労働者に通知する。 \n",
      " \n",
      " - 23 - \n",
      " ① 一般勤務 \n",
      "始業・終業時刻 休憩時間 \n",
      "始業  午前  時  分 \n",
      "  時  分から  時  分まで \n",
      "終業  午後  時  分 \n",
      " \n",
      "② 交替勤務 \n",
      " （イ）１番（日勤） \n",
      "始業・終業時刻 休憩時間 \n",
      "始業  午前  時  分 \n",
      "  時  分から  時  分まで \n",
      "終業  午後  時  分 \n",
      " \n",
      "（ロ）２番（準夜勤） \n",
      "始業・終業時刻 休憩時間 \n",
      "始業  午前  時  分 \n",
      "  時  分から  時  分まで \n",
      "終業  午後  時  分 \n",
      " \n",
      "（ハ）３番（夜勤） \n",
      "始業・終業時刻 休憩時間 \n",
      "始業  午前  時  分 \n",
      "  時  分から  時  分まで \n",
      "終業  午後  時  分 \n",
      " \n",
      "３ 交替勤務における各労働者の勤務は、別に定めるシフト表により、前月の   日\n",
      "までに各労働者に通知する。\n"
     ]
    }
   ],
   "source": [
    "# Azure AI SearchのAPIに接続するためのクライアントを生成する\n",
    "searchClient = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=\"docs\",\n",
    "    credential=AzureKeyCredential(search_api_key)\n",
    ")\n",
    "\n",
    "# ベクトルクエリの作成\n",
    "vector_query = VectorizedQuery(\n",
    "    vector=vectorized_prompt,\n",
    "    k_nearest_neighbors=3,  # 上位3件の結果を取得します\n",
    "    fields=\"contentVector\"  # ベクトル検索を行うフィールドを指定します\n",
    ")\n",
    "\n",
    "# ベクトル検索の実行\n",
    "results = searchClient.search(\n",
    "    search_text='',  # ベクトル検索のみ行うためテキストクエリは空\n",
    "    vector_queries=[vector_query],\n",
    "    select=['id', 'content'],\n",
    ")\n",
    "\n",
    "# 最初の検索結果を取得\n",
    "first_result = next(results, None)\n",
    "if first_result:\n",
    "    print(first_result[\"content\"])\n",
    "else:\n",
    "    print(\"検索結果が見つかりませんでした\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure OpenAIに回答生成依頼\n",
    "\n",
    "1. **システムメッセージの定義**: GPT-4o-miniに対するシステムメッセージを定義し、AIのキャラクターや回答スタイルを設定します。\n",
    "2. **ユーザーメッセージの作成**: 検索クエリと検索結果を含むユーザーメッセージを作成します。\n",
    "3. **回答生成の依頼**: Azure OpenAIに対して、ユーザーメッセージに基づいた回答を生成するよう依頼します。\n",
    "4. **回答の表示**: 生成された回答を表示します。\n",
    "\n",
    "以下のコードを実行して、ベクトル検索の結果に基づいた回答を生成します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 労働時間について、週間４４時間までの働かせることが認められ、１日の労働時間の上限は８時間と法律で定められている。\n",
      "2. 休憩時間について、1日の労働時間が６時間を超える場合には少なくとも４５分、８時間を超える場合には少なくとも１時間の休憩時間を与えなければならない。 \n",
      "3. 休日については、毎週少なくとも１回又は４週間を通じ４日以上与えなければならない。\n"
     ]
    }
   ],
   "source": [
    "# Azure OpenAIクライアントの作成\n",
    "openAIClient = AzureOpenAI(\n",
    "    api_key=aoai_api_key,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_endpoint=aoai_endpoint\n",
    ")\n",
    "\n",
    "# システムメッセージの定義\n",
    "system_message_chat_conversation = \"\"\"\n",
    "あなたはユーザーの質問に回答するチャットボットです。\n",
    "回答については、「Sources:」以下に記載されている内容に基づいて回答してください。\n",
    "回答は簡潔にしてください。\n",
    "「Sources:」に記載されている情報以外の回答はしないでください。\n",
    "また、ユーザーの質問に対して、Sources:以下に記載されている内容に基づいて適切な回答ができない場合は、「すみません。わかりません。」と回答してください。\n",
    "回答の中に情報源の提示は含めないでください。例えば、回答の中に「Sources:」という形で情報源を示すことはしないでください。\n",
    "\"\"\"\n",
    "\n",
    "# ユーザーメッセージの作成\n",
    "user_message = \"\"\"\n",
    "{query}\n",
    "\n",
    "Sources:\n",
    "{source}\n",
    "\"\"\".format(query=prompt, source=first_result[\"content\"])\n",
    "\n",
    "# メッセージリストの作成\n",
    "messages_for_vector_answer = [\n",
    "    {\"role\": \"system\", \"content\": system_message_chat_conversation},\n",
    "    {\"role\": \"user\", \"content\": user_message}\n",
    "]\n",
    "\n",
    "# Azure OpenAI Serviceに回答生成を依頼\n",
    "response = openAIClient.chat.completions.create(\n",
    "    model=\"gpt-4o-mini-deploy\",\n",
    "    messages=messages_for_vector_answer\n",
    ")\n",
    "\n",
    "# 生成された回答を表示\n",
    "response_text = response.choices[0].message.content\n",
    "print(response_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハンズオンは以上になります\n",
    "終了された方は、不要なコストの発生を避けるためにお手数ですがAzureリソースの削除・Codespacesの停止をお願い申し上げます。\n",
    "また、早めに終了された方のために、[追加コンテンツ](#extra1)もご用意しておりますので、リソース削除前にご利用ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"delete\"></a>\n",
    "## Azureリソースの削除方法\n",
    "不要なコストの発生を避けるために以下の手順でリソースを削除しましょう。\n",
    "\n",
    "- [Azure Portal](https://portal.azure.com/)にアクセスします。画面上部の検索ボックスに「リソースグループ」と入力し、「リソースグループ」というサービスをクリックしてください。\n",
    "![Image 5](../assets/delete1.png)\n",
    "\n",
    "- リソースグループの一覧が表示されるので、このセミナーのために作成したリソースグループをクリックしてください。\n",
    "- リソースグループの「概要」タブの上部にある「リソースグループの削除」をクリックしてください。\n",
    "![Image 6](../assets/delete2.png)\n",
    "\n",
    "- 展開されたページ下部の入力欄にリソースグループ名を入力して、「削除」ボタンをクリックしてください。リソースグループに依存するAzure OpenAI ServiceやAzure AI Searchのリソースも同時に削除されます。\n",
    "![Image 7](../assets/delete3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codespacesの停止方法\n",
    "ハンズオン終了時には、課金が発生しないように忘れずにCodespacesを停止してください。Forkしたリポジトリに移動して、AcitiveなCodespaces横の三点リーダーを展開して、「Stop codespaces」をクリックしてください。\n",
    "\n",
    "![Image 4](../assets/stop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"extra1\"></a>\n",
    "## 追加コンテンツ\n",
    "2つの追加コンテンツを用意しました。お時間ある方は試してみてください。\n",
    "\n",
    "- もっといろんなことを聞いてみよう\n",
    "- [チャンクサイズの変化による回答内容の変化](#extra2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### もっといろんなことを聞いてみよう\n",
    "\n",
    "以下のセルを実行するとプロンプトの入力が求められるので、[モデル就業規則](https://www.mhlw.go.jp/content/001018385.pdf)に関して色々聞いてみましょう。全く関係ないことを聞いた場合にはどんな回答が得られるか試してみましょう。また、モデルの振る舞いを制御したり、性格付けするための`system_message_chat_conversation`を自由に書き換えて、生成される回答がどのように変わるか体験してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ベクトル化したプロンプト[-0.007567174732685089, 0.01277646142989397, 0.07194299250841141, -0.009398650377988815, 0.03917383775115013, 0.012919032014906406, 0.012765495106577873, -0.005538294557482004, 0.021451294422149658, -0.01731676608324051, 0.0035368315875530243, 0.050316229462623596, -0.009097060188651085, 0.009820876643061638, -0.010478892363607883, -0.03226467967033386, -0.019872058182954788, -0.03000549226999283, 0.021506130695343018, 0.04116981849074364, 0.011953942477703094, 0.024368496611714363, -0.024851040914654732, 0.03366844356060028, 0.005922136828303337, -0.013522212393581867, 0.035159945487976074, -0.002153628971427679, 0.024280760437250137, -0.05062330141663551, -0.0041701714508235455, -0.04320966452360153, -0.005724732298403978, -0.008680317550897598, -0.005409433040767908, 0.03362457826733589, 0.014662771485745907, 0.026627682149410248, -0.00857613142579794, -0.0404021330177784, -0.014070558361709118, -0.020617809146642685, 0.040116991847753525, -0.07957597076892853, -0.043275464326143265, 0.044635362923145294, -0.05106198042631149, 0.06110767647624016, 0.012392619624733925, 0.04375800862908363]\n",
      "労働基準法によると、１日の労働時間の上限は８時間です。労働時間は、１週間については４０時間まで、１日については８時間までとなっています。休憩時間については、１日の労働時間が６時間を超える場合には少なくとも４５分、８時間を超える場合には少なくとも１時間の休憩時間を与えなければなりません。労働基準法の規定に適合する労働条件を実現するためには、週休２日制、週休１日制で１日の所定労働時間を短く設定する、または変形労働時間制を導入するなどの方法があります。\n"
     ]
    }
   ],
   "source": [
    "# プロンプトをベクトル化\n",
    "user_prompt = input(\"プロンプトを入力してください: \")\n",
    "vectorized_user_prompt = generate_embeddings(user_prompt)\n",
    "print(f\"ベクトル化したプロンプト{vectorized_prompt[:50]}\")\n",
    "\n",
    "# ベクトルクエリの作成\n",
    "vector_query = VectorizedQuery(\n",
    "    vector=vectorized_user_prompt,\n",
    "    k_nearest_neighbors=3,  # 上位3件の結果を取得します\n",
    "    fields=\"contentVector\"  # ベクトル検索を行うフィールドを指定します\n",
    ")\n",
    "\n",
    "# ベクトル検索の実行\n",
    "results = searchClient.search(\n",
    "    search_text='',  # ベクトル検索のみ行うためテキストクエリは空\n",
    "    vector_queries=[vector_query],\n",
    "    select=['id', 'content'],\n",
    ")\n",
    "\n",
    "# 最初の検索結果を取得\n",
    "first_result = next(results, None)\n",
    "if not first_result:\n",
    "    print(\"検索結果が見つかりませんでした\")\n",
    "\n",
    "# システムメッセージの定義\n",
    "system_message_chat_conversation= \"\"\"\n",
    "あなたはユーザーの質問に回答するチャットボットです。\n",
    "回答については、「Sources:」以下に記載されている内容に基づいて回答してください。\n",
    "回答は簡潔にしてください。\n",
    "「Sources:」に記載されている情報以外の回答はしないでください。\n",
    "また、ユーザーの質問に対して、Sources:以下に記載されている内容に基づいて適切な回答ができない場合は、「すみません。わかりません。」と回答してください。\n",
    "回答の中に情報源の提示は含めないでください。例えば、回答の中に「Sources:」という形で情報源を示すことはしないでください。\n",
    "\"\"\"\n",
    "\n",
    "# ユーザーメッセージの作成\n",
    "user_message = \"\"\"\n",
    "{query}\n",
    "\n",
    "Sources:\n",
    "{source}\n",
    "\"\"\".format(query=user_prompt, source=first_result[\"content\"])\n",
    "\n",
    "# メッセージリストの作成\n",
    "messages_for_vector_answer = [\n",
    "    {\"role\": \"system\", \"content\": system_message_chat_conversation},\n",
    "    {\"role\": \"user\", \"content\": user_message}\n",
    "]\n",
    "\n",
    "# Azure OpenAI Serviceに回答生成を依頼\n",
    "response = openAIClient.chat.completions.create(\n",
    "    model=\"gpt-4o-mini-deploy\",\n",
    "    messages=messages_for_vector_answer\n",
    ")\n",
    "\n",
    "# 生成された回答を表示\n",
    "response_text = response.choices[0].message.content\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"extra2\"></a>\n",
    "## チャンクサイズによる回答内容の変化\n",
    "\n",
    "ハンズオンの中では、チャンクサイズを1000としてインデクシングをしました。ここでは、チャンクサイズを3000とした際のRAGの回答内容の変化を見てみましょう。流れとしては、以下のとおりです。\n",
    "\n",
    "1. チャンクサイズ3000のドキュメントをインデクシングするためのインデックス「docs2」を作成する\n",
    "2. チャンクサイズ3000,オーバーラップ600でドキュメントをチャンク化する（チャンクサイズが小さいので終了までに）\n",
    "3. チャンク化したドキュメントをdocs2にインデクシングする\n",
    "4. 任意のプロンプトで回答を依頼する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "インデックス 'docs2' が作成されました\n"
     ]
    }
   ],
   "source": [
    "# インデックス「docs2」を作成する\n",
    "def create_index(index_name):\n",
    "    \"\"\"\n",
    "    Azure AI Searchのインデックスを作成する\n",
    "    \"\"\"\n",
    "    client = SearchIndexClient(endpoint=search_endpoint, credential=AzureKeyCredential(search_api_key))\n",
    "\n",
    "    # すでにインデックスが作成済みである場合には何もしない\n",
    "    if index_name in client.list_index_names():\n",
    "        print(f\"インデックス '{index_name}' はすでに作成済みです\")\n",
    "        return\n",
    "\n",
    "    # インデックスのフィールドを定義する\n",
    "    fields = [\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchableField(name=\"content\", type=\"Edm.String\", analyzer_name=\"ja.microsoft\"),\n",
    "        SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                    searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\")\n",
    "    ]\n",
    "\n",
    "    # ベクトル検索のための定義を行う\n",
    "    vector_search = VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"myHnsw\"\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"myHnswProfile\",\n",
    "                algorithm_configuration_name=\"myHnsw\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # インデックスを作成する\n",
    "    index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)\n",
    "    client.create_index(index)\n",
    "    print(f\"インデックス '{index_name}' が作成されました\")\n",
    "\n",
    "# インデックス名を指定してインデックスを作成する\n",
    "index_name = \"docs2\"\n",
    "create_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "チャンク化完了\n"
     ]
    }
   ],
   "source": [
    "def create_chunk(content: str, separator: str, chunk_size: int = 512, overlap: int = 0):\n",
    "    \"\"\"\n",
    "    テキストを指定したサイズで分割する\n",
    "    \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_overlap=overlap, chunk_size=chunk_size, separators=separator)\n",
    "    chunks = splitter.split_text(content)\n",
    "    return chunks\n",
    "\n",
    "# テキストを指定したサイズで分割する\n",
    "chunksize = 3000  # チャンクサイズ\n",
    "overlap = 600  # オーバーラップサイズ\n",
    "separator = [\"\\n\\n\", \"\\n\", \"。\", \"、\", \" \", \"\"]  # 区切り文字\n",
    "chunks2 = create_chunk(content, separator, chunksize, overlap)\n",
    "print(\"チャンク化完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1個目のチャンクを処理中...\n",
      "2個目のチャンクを処理中...\n",
      "3個目のチャンクを処理中...\n",
      "4個目のチャンクを処理中...\n",
      "5個目のチャンクを処理中...\n",
      "6個目のチャンクを処理中...\n",
      "7個目のチャンクを処理中...\n",
      "8個目のチャンクを処理中...\n",
      "9個目のチャンクを処理中...\n",
      "10個目のチャンクを処理中...\n",
      "11個目のチャンクを処理中...\n",
      "12個目のチャンクを処理中...\n",
      "13個目のチャンクを処理中...\n",
      "14個目のチャンクを処理中...\n",
      "15個目のチャンクを処理中...\n",
      "16個目のチャンクを処理中...\n",
      "17個目のチャンクを処理中...\n",
      "18個目のチャンクを処理中...\n",
      "19個目のチャンクを処理中...\n",
      "20個目のチャンクを処理中...\n",
      "21個目のチャンクを処理中...\n",
      "22個目のチャンクを処理中...\n",
      "23個目のチャンクを処理中...\n",
      "24個目のチャンクを処理中...\n",
      "25個目のチャンクを処理中...\n",
      "26個目のチャンクを処理中...\n",
      "27個目のチャンクを処理中...\n",
      "28個目のチャンクを処理中...\n",
      "29個目のチャンクを処理中...\n",
      "30個目のチャンクを処理中...\n",
      "31個目のチャンクを処理中...\n",
      "32個目のチャンクを処理中...\n",
      "33個目のチャンクを処理中...\n",
      "インデクシング完了\n"
     ]
    }
   ],
   "source": [
    "# テキストをAzure AI Searchのdocs2にインデックスする\n",
    "def index_docs(chunks: list):\n",
    "    \"\"\"\n",
    "    ドキュメントをAzure AI Searchにインデックスする\n",
    "    \"\"\"\n",
    "    # Azure AI SearchのAPIに接続するためのクライアントを生成する\n",
    "    searchClient = SearchClient(\n",
    "        endpoint=search_endpoint,\n",
    "        index_name=\"docs2\",\n",
    "        credential=AzureKeyCredential(search_api_key)\n",
    "    )\n",
    "\n",
    "    # Azure OpenAIのAPIに接続するためのクライアントを生成する\n",
    "    openAIClient = AzureOpenAI(\n",
    "        api_key=aoai_api_key,\n",
    "        api_version=aoai_api_version,\n",
    "        azure_endpoint=aoai_endpoint\n",
    "    )\n",
    "\n",
    "    # チャンク化されたテキストとそのテキストのベクトルをAzure AI Searchにアップロードする\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"{i+1}個目のチャンクを処理中...\")\n",
    "        response = openAIClient.embeddings.create(\n",
    "            input=chunk,\n",
    "            model=\"text-embedding-3-small-deploy\"\n",
    "        )\n",
    "\n",
    "        # チャンク化されたテキストとそのテキストのベクトルをAzure AI Searchにアップロードする\n",
    "        document = {\"id\": str(i), \"content\": chunk, \"contentVector\": response.data[0].embedding}\n",
    "        searchClient.upload_documents([document])\n",
    "    print(\"インデクシング完了\")\n",
    "\n",
    "# テキストをAzure AI Searchにインデックスする\n",
    "index_docs(chunks2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プロンプトをベクトル化\n",
    "user_prompt = input(\"プロンプトを入力してください: \")\n",
    "vectorized_user_prompt = generate_embeddings(user_prompt)\n",
    "print(f\"ベクトル化したプロンプト{vectorized_prompt[:50]}\")\n",
    "\n",
    "searchClient = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=\"docs2\",\n",
    "    credential=AzureKeyCredential(search_api_key)\n",
    ")\n",
    "\n",
    "# ベクトルクエリの作成\n",
    "vector_query = VectorizedQuery(\n",
    "    vector=vectorized_user_prompt,\n",
    "    k_nearest_neighbors=3,  # 上位3件の結果を取得します\n",
    "    fields=\"contentVector\"  # ベクトル検索を行うフィールドを指定します\n",
    ")\n",
    "\n",
    "# ベクトル検索の実行\n",
    "results = searchClient.search(\n",
    "    search_text='',  # ベクトル検索のみ行うためテキストクエリは空\n",
    "    vector_queries=[vector_query],\n",
    "    select=['id', 'content'],\n",
    ")\n",
    "\n",
    "# 最初の検索結果を取得\n",
    "first_result = next(results, None)\n",
    "if not first_result:\n",
    "    print(\"検索結果が見つかりませんでした\")\n",
    "\n",
    "# システムメッセージの定義\n",
    "system_message_chat_conversation= \"\"\"\n",
    "あなたはユーザーの質問に回答するチャットボットです。\n",
    "回答については、「Sources:」以下に記載されている内容に基づいて回答してください。\n",
    "回答は簡潔にしてください。\n",
    "「Sources:」に記載されている情報以外の回答はしないでください。\n",
    "また、ユーザーの質問に対して、Sources:以下に記載されている内容に基づいて適切な回答ができない場合は、「すみません。わかりません。」と回答してください。\n",
    "回答の中に情報源の提示は含めないでください。例えば、回答の中に「Sources:」という形で情報源を示すことはしないでください。\n",
    "\"\"\"\n",
    "\n",
    "# ユーザーメッセージの作成\n",
    "user_message = \"\"\"\n",
    "{query}\n",
    "\n",
    "Sources:\n",
    "{source}\n",
    "\"\"\".format(query=user_prompt, source=first_result[\"content\"])\n",
    "\n",
    "# メッセージリストの作成\n",
    "messages_for_vector_answer = [\n",
    "    {\"role\": \"system\", \"content\": system_message_chat_conversation},\n",
    "    {\"role\": \"user\", \"content\": user_message}\n",
    "]\n",
    "\n",
    "# Azure OpenAI Serviceに回答生成を依頼\n",
    "response = openAIClient.chat.completions.create(\n",
    "    model=\"gpt-4o-mini-deploy\",\n",
    "    messages=messages_for_vector_answer\n",
    ")\n",
    "\n",
    "# 生成された回答を表示\n",
    "response_text = response.choices[0].message.content\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 追加コンテンツは以上になります\n",
    "不要なコストの発生を避けるために[Azureリソースの削除・Codespacesの停止](#delete)をお願い申し上げます。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
